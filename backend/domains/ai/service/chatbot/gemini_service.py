"""
ğŸ¤– Gemini AI Service for ALMAENG Chatbot

Google Gemini APIë¥¼ ì‚¬ìš©í•œ ë²”ìš© AI ì„œë¹„ìŠ¤.
ë…ë¦½ì ìœ¼ë¡œ ì¡´ì¬í•˜ë©°, í•„ìš”í•œ ë„ë©”ì¸ì—ì„œ interfaceë¥¼ í†µí•´ í˜¸ì¶œ.

âœ… DAEMON Pattern: Stateless, Pure AI Service
Module Version: 2026-01-26-v4 (Clean)
"""

import os
from dataclasses import dataclass

from django.conf import settings
from google import genai


@dataclass
class ChatResponse:
    """ì±—ë´‡ ì‘ë‹µ ë°ì´í„°"""

    answer: str
    sources: list[dict] | None = None
    is_on_topic: bool = True


class GeminiChatService:
    """
    Gemini ê¸°ë°˜ ë²”ìš© AI ì±—ë´‡ ì„œë¹„ìŠ¤

    âœ… DAEMON Pattern:
    - ë…ë¦½ì ì¸ AI ì„œë¹„ìŠ¤ (ë„ë©”ì¸ ì˜ì¡´ì„± ì—†ìŒ)
    - ì»¨í…ìŠ¤íŠ¸ëŠ” í˜¸ì¶œìê°€ ì œê³µ
    - ìˆœìˆ˜ í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤
    """

    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY") or getattr(settings, "GEMINI_API_KEY", None)
        if not api_key:
            raise ValueError("GEMINI_API_KEY not configured")

        self.client = genai.Client(api_key=api_key)
        self.model = "gemini-2.0-flash-exp"

    def generate(
        self,
        prompt: str,
        system_instruction: str | None = None,
    ) -> str:
        """
        Generate response from Gemini

        âœ… Pure function: No DB, No side effects

        Args:
            prompt: User prompt
            system_instruction: System instruction (optional)

        Returns:
            Generated text
        """
        try:
            contents = prompt
            if system_instruction:
                contents = f"{system_instruction}\n\n{prompt}"

            response = self.client.models.generate_content(
                model=self.model,
                contents=contents,
            )
            return response.text.strip()
        except Exception as e:
            return f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e!s}"

    def chat(
        self,
        question: str,
        context: str | None = None,
        system_instruction: str | None = None,
    ) -> ChatResponse:
        """
        Chat with context

        âœ… DAEMON Pattern: ContextëŠ” í˜¸ì¶œìê°€ ì œê³µ

        Args:
            question: User question
            context: Additional context (optional)
            system_instruction: System instruction (optional)

        Returns:
            ChatResponse
        """
        # Build prompt
        prompt_parts = []

        if system_instruction:
            prompt_parts.append(f"[System]\n{system_instruction}")

        if context:
            prompt_parts.append(f"[Context]\n{context}")

        prompt_parts.append(f"[Question]\n{question}")

        full_prompt = "\n\n".join(prompt_parts)

        # Generate response
        answer = self.generate(full_prompt)

        return ChatResponse(
            answer=answer,
            sources=None,
            is_on_topic=True,
        )


# ============================================
# Singleton Instance (Performance)
# ============================================

_gemini_service: GeminiChatService | None = None


def get_gemini_service() -> GeminiChatService:
    """
    Get Gemini service singleton

    âœ… DAEMON Pattern: Singleton Model Loader
    - Load once, use forever
    - Prevents repeated initialization
    """
    global _gemini_service
    if _gemini_service is None:
        _gemini_service = GeminiChatService()
    return _gemini_service


# ============================================
# Public Interface Functions
# ============================================

def ask_question(
    question: str,
    context: str | None = None,
    system_instruction: str | None = None,
) -> ChatResponse:
    """
    Ask question to Gemini AI

    âœ… Public Interface: ë‹¤ë¥¸ ë„ë©”ì¸ì—ì„œ í˜¸ì¶œ

    Args:
        question: User question
        context: Additional context (optional)
        system_instruction: System instruction (optional)

    Returns:
        ChatResponse
    """
    service = get_gemini_service()
    return service.chat(question, context, system_instruction)


def generate_text(
    prompt: str,
    system_instruction: str | None = None,
) -> str:
    """
    Generate text from Gemini AI

    âœ… Public Interface: ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„±

    Args:
        prompt: User prompt
        system_instruction: System instruction (optional)

    Returns:
        Generated text
    """
    service = get_gemini_service()
    return service.generate(prompt, system_instruction)
