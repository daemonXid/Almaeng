"""
ğŸ•·ï¸ Base Crawler

ê³µí†µ í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤. Rate limiting, retry, error handling.
"""

import asyncio
import random
from abc import ABC, abstractmethod
from dataclasses import dataclass
from decimal import Decimal

import httpx


@dataclass
class CrawlResult:
    """í¬ë¡¤ë§ ê²°ê³¼"""

    product_name: str
    price: Decimal
    original_price: Decimal | None = None
    discount_percent: int | None = None
    url: str = ""
    is_in_stock: bool = True
    platform: str = ""
    error: str | None = None


class BaseCrawler(ABC):
    """í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    PLATFORM_NAME = "base"
    BASE_URL = ""

    # Rate limiting
    MIN_DELAY = 1.0  # ìµœì†Œ ìš”ì²­ ê°„ê²© (ì´ˆ)
    MAX_DELAY = 3.0  # ìµœëŒ€ ìš”ì²­ ê°„ê²© (ì´ˆ)
    MAX_RETRIES = 3

    # User agents rotation
    USER_AGENTS = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    ]

    def __init__(self):
        self._client: httpx.AsyncClient | None = None

    @property
    def headers(self) -> dict:
        """ëœë¤ User-Agent í¬í•¨ í—¤ë”"""
        return {
            "User-Agent": random.choice(self.USER_AGENTS),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
        }

    async def get_client(self) -> httpx.AsyncClient:
        """HTTP í´ë¼ì´ì–¸íŠ¸ (ì‹±ê¸€í†¤)"""
        if self._client is None or self._client.is_closed:
            self._client = httpx.AsyncClient(
                headers=self.headers,
                timeout=30.0,
                follow_redirects=True,
            )
        return self._client

    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        if self._client:
            await self._client.aclose()

    async def delay(self):
        """Rate limiting delay"""
        await asyncio.sleep(random.uniform(self.MIN_DELAY, self.MAX_DELAY))

    async def fetch(self, url: str, retries: int = 0) -> str | None:
        """URL fetch with retry"""
        try:
            client = await self.get_client()
            response = await client.get(url)
            response.raise_for_status()
            await self.delay()
            return response.text
        except httpx.HTTPStatusError:
            if retries < self.MAX_RETRIES:
                await asyncio.sleep(2**retries)  # Exponential backoff
                return await self.fetch(url, retries + 1)
            return None
        except Exception:
            return None

    @abstractmethod
    async def search(self, keyword: str) -> list[CrawlResult]:
        """í‚¤ì›Œë“œë¡œ ì œí’ˆ ê²€ìƒ‰"""
        pass

    @abstractmethod
    async def get_price(self, product_url: str) -> CrawlResult | None:
        """ì œí’ˆ URLì—ì„œ ê°€ê²© ì •ë³´ ì¶”ì¶œ"""
        pass

    def parse_price(self, price_text: str) -> Decimal:
        """ê°€ê²© ë¬¸ìì—´ â†’ Decimal ë³€í™˜"""
        # "â‚©12,900" â†’ 12900
        cleaned = "".join(c for c in price_text if c.isdigit())
        return Decimal(cleaned) if cleaned else Decimal(0)

    def calculate_discount(self, original: Decimal, current: Decimal) -> int:
        """í• ì¸ìœ¨ ê³„ì‚°"""
        if original <= 0:
            return 0
        return int(((original - current) / original) * 100)
